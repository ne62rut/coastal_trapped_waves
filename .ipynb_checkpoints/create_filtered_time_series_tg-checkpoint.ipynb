{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract and filter tide gauge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cartopy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-326ca467c3da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxarray\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcartopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mccrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcartopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcfeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cartopy'"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import numpy as np\n",
    "from matplotlib.path import Path\n",
    "import math\n",
    "from shapely.geometry import Point, LineString, MultiLineString\n",
    "import os\n",
    "from matplotlib.colors import Normalize\n",
    "from scipy.signal import butter, filtfilt\n",
    "from fuzzywuzzy import process\n",
    "from ctw_functions import butter_bandpass, butter_bandpass_filter, interpolate_nan, find_nearest_non_nan\n",
    "\n",
    "\n",
    "\n",
    "# Function to calculate distance using the Haversine formula\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lon1, lat1, lon2, lat2 = map(math.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    r = 6371  # Radius of Earth in kilometers\n",
    "    distance = r * c\n",
    "    return distance\n",
    "\n",
    "# Function to check if points are inside a polygon\n",
    "def points_in_polygon(points, polygon):\n",
    "    path = Path(polygon)\n",
    "    return path.contains_points(points)\n",
    "\n",
    "# Function to filter points to ensure a minimum distance between them\n",
    "def filter_by_distance(coords, min_distance_km):\n",
    "    filtered_coords = []\n",
    "    for coord in coords:\n",
    "        if all(haversine(coord['longitude'], coord['latitude'], fc['longitude'], fc['latitude']) >= min_distance_km for fc in filtered_coords):\n",
    "            filtered_coords.append(coord)\n",
    "    return filtered_coords\n",
    "\n",
    "# Function to calculate distance from coastline\n",
    "def distance_from_coastline(lon, lat, coastline):\n",
    "    point = Point(lon, lat)\n",
    "    min_distance = float('inf')\n",
    "    for geom in coastline:\n",
    "        if isinstance(geom, (LineString, MultiLineString)):\n",
    "            if isinstance(geom, LineString):\n",
    "                distance = geom.distance(point) * 111  # Convert degrees to kilometers\n",
    "            else:  # MultiLineString\n",
    "                distance = min(line.distance(point) for line in geom.geoms) * 111  # Convert degrees to kilometers\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "    return min_distance\n",
    "\n",
    "# Function to calculate distance from rivers\n",
    "def distance_from_river(lon, lat, rivers):\n",
    "    point = Point(lon, lat)\n",
    "    min_distance = float('inf')\n",
    "    for geom in rivers:\n",
    "        if isinstance(geom, (LineString, MultiLineString)):\n",
    "            if isinstance(geom, LineString):\n",
    "                distance = geom.distance(point) * 111  # Convert degrees to kilometers\n",
    "            else:  # MultiLineString\n",
    "                distance = min(line.distance(point) for line in geom.geoms) * 111  # Convert degrees to kilometers\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "    return min_distance\n",
    "\n",
    "\n",
    "# Choose the dates\n",
    "start_date='2023-08-29'\n",
    "end_date='2023-11-30'\n",
    "\n",
    "\n",
    "# Choose the region\n",
    "region = 'EAST_AUSTRALIA'\n",
    "\n",
    "\n",
    "# # # EAST_AUSTRALIA\n",
    "# # parallelogram_vertices = np.array([\n",
    "# #     [149, -38],  # Bottom-left\n",
    "# #     [158, -38],  # Bottom-right\n",
    "# #     [158, -25],  # Top-right\n",
    "# #     [149, -25]   # Top-left\n",
    "# # ])\n",
    "\n",
    "# # # NORWAY\n",
    "# # parallelogram_vertices = np.array([\n",
    "# #     [5, 58],  # Bottom-left\n",
    "# #     [7, 58],  # Bottom-right\n",
    "# #     [20, 70],  # Top-right\n",
    "# #     [5, 70]   # Top-left\n",
    "# # ])\n",
    "\n",
    "# # # NORTH_WEST_AMERICA\n",
    "# # parallelogram_vertices = np.array([\n",
    "# #     [-119, 32],  # Bottom-left\n",
    "# #     [-116, 32],  # Bottom-right\n",
    "# #     [-123, 47],  # Top-right\n",
    "# #     [-127, 47]   # Top-left\n",
    "# # ])\n",
    "\n",
    "# NORTH_EAST_AMERICA\n",
    "# parallelogram_vertices = np.array([\n",
    "#     [-80, 24],  # Bottom-left\n",
    "#     [-79.05, 26.2],  # Bottom-right\n",
    "#     [-74, 47],  # Top-right\n",
    "#     [-84, 36.06]   # Top-left\n",
    "# ])\n",
    "\n",
    "\n",
    "# Define the vertices of the parallelogram for EAST_AUSTRALIA\n",
    "parallelogram_vertices = np.array([\n",
    "    [149, -38],  # Bottom-left\n",
    "    [158, -38],  # Bottom-right\n",
    "    [158, -25],  # Top-right\n",
    "    [149, -25]   # Top-left\n",
    "])\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "#file_path = '/DGFI8/H/work_marcello/machine_learning_altimetry_validation/gesla_2004_selected_lowess_dac_correctedglobal.nc'\n",
    "file_path = '/DGFI8/H/work_marcello/machine_learning_altimetry_validation/gesla_2023_selected_lowess_dac_correctedaustralia.nc'\n",
    "\n",
    "ds = xr.open_dataset(file_path)\n",
    "\n",
    "# Subsample the dataset based on the date range\n",
    "ds = ds.sel(date_time=slice(start_date, end_date))\n",
    "\n",
    "# Extract the relevant variables\n",
    "latitudes = ds['latitude'].values\n",
    "longitudes = ds['longitude'].values\n",
    "site_names = ds['site_name'].values\n",
    "\n",
    "# Combine latitudes and longitudes into a single array of points\n",
    "points = np.vstack((longitudes, latitudes)).T\n",
    "\n",
    "# Filter locations based on the parallelogram\n",
    "selected_indices = points_in_polygon(points, parallelogram_vertices)\n",
    "\n",
    "selected_sites = site_names[selected_indices]\n",
    "selected_coords = [{\n",
    "    'site_name': site_name,\n",
    "    'latitude': latitudes[i],\n",
    "    'longitude': longitudes[i]\n",
    "} for i, site_name in enumerate(site_names) if selected_indices[i]]\n",
    "\n",
    "# Filter the selected coordinates to ensure a minimum distance of 50 km\n",
    "min_distance_km = 50\n",
    "filtered_coords = filter_by_distance(selected_coords, min_distance_km)\n",
    "\n",
    "# Load coastline data\n",
    "coastline = list(cfeature.COASTLINE.geometries())\n",
    "rivers = list(cfeature.RIVERS.geometries())\n",
    "\n",
    "# Check if all geometries are valid\n",
    "if not all(isinstance(geom, (LineString, MultiLineString)) for geom in coastline + rivers):\n",
    "    print(\"Error: Some geometries are not LineString or MultiLineString.\")\n",
    "\n",
    "\n",
    "\n",
    "# Filter coordinates based on proximity to coastline (within 10 km) and not near river mouths (more than 1 km)\n",
    "max_distance_km = 10\n",
    "min_river_distance_km = 25\n",
    "final_coords = []\n",
    "for coord in filtered_coords:\n",
    "    distance_to_coastline = distance_from_coastline(coord['longitude'], coord['latitude'], coastline)\n",
    "    distance_to_river = distance_from_river(coord['longitude'], coord['latitude'], rivers)\n",
    "    if distance_to_coastline <= max_distance_km and distance_to_river > min_river_distance_km:\n",
    "        print(distance_to_coastline)\n",
    "        print(distance_to_river)\n",
    "        print('-----')\n",
    "        final_coords.append(coord)\n",
    "\n",
    "# Sort the final coordinates from south to north\n",
    "final_coords_sorted = sorted(final_coords, key=lambda x: x['latitude'])\n",
    "\n",
    "# Extract sorted site names and coordinates\n",
    "selected_locations = [coord['site_name'] for coord in final_coords_sorted]\n",
    "locations = {coord['site_name']: {'latitude': coord['latitude'], 'longitude': coord['longitude']} for coord in final_coords_sorted}\n",
    "\n",
    "# Print selected locations and their coordinates\n",
    "print(\"Selected Locations:\", selected_locations)\n",
    "print(\"Locations:\", locations)\n",
    "\n",
    "# Plot the map\n",
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "ax.set_extent([np.min(parallelogram_vertices[:, 0]) - 10, np.max(parallelogram_vertices[:, 0]) + 10,\n",
    "               np.min(parallelogram_vertices[:, 1]) - 10, np.max(parallelogram_vertices[:, 1]) + 10])\n",
    "\n",
    "# Add geographic features\n",
    "ax.add_feature(cfeature.LAND)\n",
    "ax.add_feature(cfeature.OCEAN)\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "ax.add_feature(cfeature.LAKES, alpha=0.5)\n",
    "ax.add_feature(cfeature.RIVERS)\n",
    "\n",
    "# Plot all locations\n",
    "ax.scatter(longitudes, latitudes, color='blue', marker='o', s=20, transform=ccrs.PlateCarree(), label='All Locations')\n",
    "\n",
    "# Highlight selected locations\n",
    "for site_name in selected_locations:\n",
    "    coord = locations[site_name]\n",
    "    ax.scatter(coord['longitude'], coord['latitude'], color='red', marker='x', s=50, transform=ccrs.PlateCarree(), label=site_name)\n",
    "\n",
    "# Plot the parallelogram\n",
    "parallelogram_path = np.vstack((parallelogram_vertices, parallelogram_vertices[0]))\n",
    "ax.plot(parallelogram_path[:, 0], parallelogram_path[:, 1], color='green', linestyle='--', transform=ccrs.PlateCarree(), label='Parallelogram')\n",
    "\n",
    "# Add legend\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "# Add gridlines\n",
    "ax.gridlines(draw_labels=True)\n",
    "\n",
    "plt.title('Selected Locations within Parallelogram with Minimum Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the output directory\n",
    "output_dir = '/DGFI8/H/work_marcello/coastal_trapped_waves_data/filtered_time_series_tidegauges'\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
    "\n",
    "# Load the dataset\n",
    "dataset = xr.open_dataset(file_path)\n",
    "\n",
    "# Subsample the dataset based on the date range\n",
    "dataset = dataset.sel(date_time=slice(start_date, end_date))\n",
    "\n",
    "# Convert hourly data to daily means\n",
    "daily_dataset = dataset.resample(date_time='D').mean()\n",
    "\n",
    "# Extract necessary variables\n",
    "sla_dac = daily_dataset['sla_dac'].values\n",
    "time = daily_dataset['date_time'].values\n",
    "site_names = dataset['site_name'].values\n",
    "latitudes = dataset['latitude'].values\n",
    "longitudes = dataset['longitude'].values\n",
    "\n",
    "\n",
    "\n",
    "# Frequency cutoffs in cycles per day\n",
    "lowcut = 0.035\n",
    "highcut = 0.15\n",
    "fs = 1.0  # Sampling frequency in cycles per day\n",
    "\n",
    "# Find closest matches for selected locations in the dataset's site_names\n",
    "filtered_indices = []\n",
    "valid_site_names = []\n",
    "valid_latitudes = []\n",
    "valid_longitudes = []\n",
    "\n",
    "for loc in selected_locations:\n",
    "    match = process.extractOne(loc, site_names)\n",
    "    if match[1] >= 80:  # Minimum similarity score threshold\n",
    "        idx = np.where(site_names == match[0])[0][0]\n",
    "        filtered_indices.append(idx)\n",
    "        valid_site_names.append(match[0])\n",
    "        valid_latitudes.append(latitudes[idx])\n",
    "        valid_longitudes.append(longitudes[idx])\n",
    "    else:\n",
    "        print(f\"No close match found for '{loc}'.\")\n",
    "\n",
    "# Filter sla_dac and reorder according to filtered indices\n",
    "filtered_sla_dac = sla_dac[:, filtered_indices]\n",
    "\n",
    "# Calculate the mean of each row\n",
    "row_means = np.nanmean(filtered_sla_dac, axis=0)\n",
    "\n",
    "# Subtract the row mean from each element in the row\n",
    "filtered_sla_dac_demeaned = filtered_sla_dac - row_means[np.newaxis,:]\n",
    "\n",
    "# Apply the Butterworth bandpass filter to each time series\n",
    "filtered_sla_dac_filtered = []\n",
    "for i in range(filtered_sla_dac.shape[1]):\n",
    "    series = filtered_sla_dac[:, i]\n",
    "    nan_count = np.isnan(series).sum()\n",
    "    if nan_count <= 0.9 * len(time):  # Keep if less than or equal to 90% NaNs\n",
    "        if nan_count > 0:\n",
    "            series = interpolate_nan(series)\n",
    "        series = butter_bandpass_filter(series, lowcut, highcut, fs, order=5)\n",
    "        filtered_sla_dac_filtered.append(series)\n",
    "\n",
    "filtered_sla_dac_filtered = np.array(filtered_sla_dac_filtered).T  # Transpose for correct shape\n",
    "\n",
    "# Check the shapes of the data arrays\n",
    "print(\"Shape of filtered_sla_dac_filtered:\", filtered_sla_dac_filtered.shape)\n",
    "print(\"Number of valid site names:\", len(valid_site_names))\n",
    "\n",
    "# Create the Hovmöller diagram using imshow with masked array\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "# Set normalization for the color scale\n",
    "norm = Normalize(vmin=-0.2, vmax=0.2)\n",
    "\n",
    "# Plot using imshow with masked array\n",
    "im = ax.imshow(filtered_sla_dac_filtered, aspect='auto', cmap='coolwarm', origin='lower', norm=norm)\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Location')\n",
    "ax.set_ylabel('Time')\n",
    "ax.set_title('Hovmöller Diagram of Filtered SLA Tide Gauges')\n",
    "\n",
    "# Add colorbar\n",
    "cbar = fig.colorbar(im, ax=ax)\n",
    "cbar.set_label('SLA DAC')\n",
    "\n",
    "# Set x-axis ticks and labels (locations)\n",
    "ax.set_xticks(np.arange(len(valid_site_names)))\n",
    "ax.set_xticklabels(valid_site_names, rotation=45, ha=\"right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print latitude and longitude for each selected location\n",
    "print(\"Latitude and Longitude for Selected Locations:\")\n",
    "for name, lat, lon in zip(valid_site_names, valid_latitudes, valid_longitudes):\n",
    "    print(f\"{name}: Latitude {lat}, Longitude {lon}\")\n",
    "\n",
    "# Save the filtered data and metadata externally\n",
    "output_file = os.path.join(output_dir, 'tide_gauge_data.npz')\n",
    "np.savez(output_file,\n",
    "         filtered_sla_dac_demeaned=filtered_sla_dac_demeaned,\n",
    "         filtered_sla_dac_filtered=filtered_sla_dac_filtered, \n",
    "         valid_site_names=valid_site_names, \n",
    "         valid_latitudes=valid_latitudes, \n",
    "         valid_longitudes=valid_longitudes)\n",
    "\n",
    "print(f\"Saved data to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
